# import os
# import numpy as np
# import pandas as pd
# from sklearn.model_selection import train_test_split
# from sklearn.metrics import accuracy_score
# from sklearn.naive_bayes import MultinomialNB
# from sklearn.tree import DecisionTreeClassifier
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.svm import SVC
# from sklearn.linear_model import LogisticRegression
# from sklearn.neighbors import KNeighborsClassifier
# from sklearn.preprocessing import StandardScaler, MinMaxScaler
# from sklearn.datasets import load_wine
# import matplotlib.pyplot as plt

# # Load a smaller dataset (Wine dataset from sklearn)
# data = load_wine(as_frame=True)['data']
# data['target'] = load_wine(as_frame=True)['target']

# # Features (X) and target (y)
# X = data.drop('target', axis=1)
# y = data['target']

# # Standardize the features for most models and normalize for MultinomialNB
# scaler_standard = StandardScaler()
# scaler_minmax = MinMaxScaler()
# X_standardized = scaler_standard.fit_transform(X)
# X_normalized = scaler_minmax.fit_transform(X)

# # Split the data into training and testing sets for both scalers
# X_train_std, X_test_std, y_train, y_test = train_test_split(X_standardized, y, test_size=0.3, random_state=42)
# X_train_norm, X_test_norm, _, _ = train_test_split(X_normalized, y, test_size=0.3, random_state=42)

# # Define classifiers
# classifiers = {
#     'Multinomial Naive Bayes': (MultinomialNB(), X_train_norm, X_test_norm),
#     'Decision Tree': (DecisionTreeClassifier(), X_train_std, X_test_std),
#     'Random Forest': (RandomForestClassifier(), X_train_std, X_test_std),
#     'Support Vector Machine': (SVC(), X_train_std, X_test_std),
#     'Logistic Regression': (LogisticRegression(), X_train_std, X_test_std),
#     'K-Nearest Neighbors': (KNeighborsClassifier(), X_train_std, X_test_std)
# }

# # Train and evaluate each classifier
# results = {}
# for name, (clf, X_train, X_test) in classifiers.items():
#     clf.fit(X_train, y_train)
#     y_pred = clf.predict(X_test)
#     accuracy = accuracy_score(y_test, y_pred)
#     results[name] = accuracy

# # Compare results
# results_df = pd.DataFrame(list(results.items()), columns=['Classifier', 'Accuracy'])
# results_df = results_df.sort_values(by='Accuracy', ascending=False)

# # Display results
# print(results_df)

# # Plot results
# plt.figure(figsize=(10, 6))
# plt.bar(results_df['Classifier'], results_df['Accuracy'], color='skyblue')
# plt.xlabel('Classifier')
# plt.ylabel('Accuracy')
# plt.title('Classifier Accuracy Comparison')
# plt.xticks(rotation=45)
# plt.show()
